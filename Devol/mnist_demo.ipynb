{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alemag/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from devol import DEvol, GenomeHandler\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset\n",
    "This problem uses mnist, a handwritten digit classification problem used for many introductory deep learning examples. Here, we load the data and prepare it for use by the GPU. We also do a one-hot encoding of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_data_format(\"channels_last\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "dataset = ((x_train, y_train), (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the genome configuration\n",
    "The `GenomeHandler` class handles the constraints that are imposed upon models in a particular genetic program. In this example, a genome is allowed **up to** 6 convolutional layeres, 3 dense layers, 256 feature maps in each convolution, and 1024 nodes in each dense layer. It also specifies three possible activation functions. See `genome-handler.py` for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_conv_layers = 6\n",
    "max_dense_layers = 2 # including final softmax layer\n",
    "max_conv_kernals = 256\n",
    "max_dense_nodes = 1024\n",
    "input_shape = x_train.shape[1:]\n",
    "num_classes = 10\n",
    "\n",
    "genome_handler = GenomeHandler(max_conv_layers, max_dense_layers, max_conv_kernals, \\\n",
    "                    max_dense_nodes, input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and run the genetic program\n",
    "The next, and final, step is create a `DEvol` and run it. Here we specify a few settings pertaining to the genetic program. In this example, we have 10 generations of evolution, 20 members in each population, and 3 epochs of training used to evaluate each model's fitness. The program will save each genome's encoding, as well as the model's loss and accuracy, in a `.csv` file printed at the beginning of program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genome encoding and accuracy data stored at Mon Apr 23 23:56:38 2018.csv \n",
      "\n",
      "\n",
      "model 1/20 - generation 1/10:\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 9324s 155ms/step - loss: 14.5074 - acc: 0.0995 - val_loss: 14.4547 - val_acc: 0.1032\n",
      "\n",
      "model 2/20 - generation 1/10:\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 121s 2ms/step - loss: 0.3399 - acc: 0.8881 - val_loss: 0.2376 - val_acc: 0.9169\n",
      "\n",
      "model 3/20 - generation 1/10:\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 383s 6ms/step - loss: 6.3701 - acc: 0.5740 - val_loss: 6.2306 - val_acc: 0.6025\n",
      "\n",
      "model 4/20 - generation 1/10:\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 788s 13ms/step - loss: 0.2169 - acc: 0.9335 - val_loss: 0.0683 - val_acc: 0.9789\n",
      "\n",
      "model 5/20 - generation 1/10:\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 2.3118 - acc: 0.1123 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "\n",
      "model 6/20 - generation 1/10:\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 9374s 156ms/step - loss: 14.4294 - acc: 0.1044 - val_loss: 14.4612 - val_acc: 0.1028\n",
      "\n",
      "model 7/20 - generation 1/10:\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 2886s 48ms/step - loss: 2.3713 - acc: 0.0997 - val_loss: 2.3039 - val_acc: 0.1135\n",
      "\n",
      "model 8/20 - generation 1/10:\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "28608/60000 [=============>................] - ETA: 35:28 - loss: 2.5447 - acc: 0.1017"
     ]
    }
   ],
   "source": [
    "num_generations = 10\n",
    "population_size = 20\n",
    "num_epochs = 1\n",
    "\n",
    "devol = DEvol(genome_handler)\n",
    "model = devol.run(dataset, num_generations, population_size, num_epochs)\n",
    "model.summary()\n",
    "\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
