{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from Two_Class_MNIST import TwoClassMnist as tcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (12700, 28, 28, 1)\n",
      "12700 train samples\n",
      "2167 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, input_shape = tcm.returnDataSet(1, 2, 28)\n",
    "dataset = ((x_train, y_train), (x_test, y_test))\n",
    "RUN_NAME = \"rsmsw\"\n",
    "num_classes = 2\n",
    "batch_size = 128\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(dense_layer_sizes, filters, kernel_size, pool_size):\n",
    "    '''Creates model comprised of 2 convolutional layers followed by dense layers\n",
    "\n",
    "    dense_layer_sizes: List of layer sizes.\n",
    "        This list has one number for each layer\n",
    "    filters: Number of convolutional filters in each convolutional layer\n",
    "    kernel_size: Convolutional kernel size\n",
    "    pool_size: Size of pooling area for max pooling\n",
    "    '''\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters, kernel_size,\n",
    "                     padding='valid',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(filters, kernel_size))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    for layer_size in dense_layer_sizes:\n",
    "        model.add(Dense(layer_size))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_size_candidates = [[32], [64], [32, 32], [64, 64]]\n",
    "my_classifier = KerasClassifier(make_model, batch_size=32)\n",
    "# Embed in to dictionary\n",
    "param_dist = {\"batch_size\": [8, 16],\n",
    "              \"epochs\": [1, 2],\n",
    "              \"filters\": [8],\n",
    "              \"kernel_size\": [3],\n",
    "              \"pool_size\": [2],\n",
    "              \"dense_layer_sizes\": dense_size_candidates}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "8466/8466 [==============================] - 12s 1ms/step - loss: 0.0640 - acc: 0.9807\n",
      "Epoch 2/2\n",
      "8466/8466 [==============================] - 11s 1ms/step - loss: 0.0298 - acc: 0.9903\n",
      "Epoch 1/2\n",
      "8467/8467 [==============================] - 13s 1ms/step - loss: 0.0632 - acc: 0.9805\n",
      "Epoch 2/2\n",
      "8467/8467 [==============================] - 12s 1ms/step - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 1/2\n",
      "8467/8467 [==============================] - 13s 2ms/step - loss: 0.0731 - acc: 0.9786\n",
      "Epoch 2/2\n",
      "8467/8467 [==============================] - 12s 1ms/step - loss: 0.0358 - acc: 0.9901\n",
      "Epoch 1/1\n",
      "8466/8466 [==============================] - 13s 2ms/step - loss: 0.0735 - acc: 0.9790\n",
      "Epoch 1/1\n",
      "8467/8467 [==============================] - 12s 1ms/step - loss: 0.0906 - acc: 0.9734\n",
      "Epoch 1/1\n",
      "8467/8467 [==============================] - 11s 1ms/step - loss: 0.0738 - acc: 0.9802\n",
      "Epoch 1/2\n",
      "8466/8466 [==============================] - 16s 2ms/step - loss: 0.0685 - acc: 0.9797\n",
      "Epoch 2/2\n",
      "8466/8466 [==============================] - 17s 2ms/step - loss: 0.0365 - acc: 0.9903\n",
      "Epoch 1/2\n",
      "8467/8467 [==============================] - 16s 2ms/step - loss: 0.0647 - acc: 0.9805\n",
      "Epoch 2/2\n",
      "8467/8467 [==============================] - 15s 2ms/step - loss: 0.0412 - acc: 0.9883\n",
      "Epoch 1/2\n",
      "8467/8467 [==============================] - 16s 2ms/step - loss: 0.0627 - acc: 0.9829\n",
      "Epoch 2/2\n",
      "8467/8467 [==============================] - 16s 2ms/step - loss: 0.0366 - acc: 0.9904\n",
      "Epoch 1/2\n",
      "8466/8466 [==============================] - 13s 2ms/step - loss: 0.0751 - acc: 0.9786\n",
      "Epoch 2/2\n",
      "8466/8466 [==============================] - 12s 1ms/step - loss: 0.0417 - acc: 0.9894\n",
      "Epoch 1/2\n",
      "8467/8467 [==============================] - 11s 1ms/step - loss: 0.0743 - acc: 0.9754\n",
      "Epoch 2/2\n",
      "8467/8467 [==============================] - 10s 1ms/step - loss: 0.0393 - acc: 0.9887\n",
      "Epoch 1/2\n",
      "8467/8467 [==============================] - 11s 1ms/step - loss: 0.0799 - acc: 0.9751\n",
      "Epoch 2/2\n",
      "8467/8467 [==============================] - 13s 2ms/step - loss: 0.0412 - acc: 0.9891\n",
      "Epoch 1/1\n",
      "8466/8466 [==============================] - 15s 2ms/step - loss: 0.0558 - acc: 0.9811\n",
      "Epoch 1/1\n",
      "8467/8467 [==============================] - 15s 2ms/step - loss: 0.0628 - acc: 0.9818\n",
      "Epoch 1/1\n",
      "8467/8467 [==============================] - 16s 2ms/step - loss: 0.0658 - acc: 0.9806\n",
      "Epoch 1/2\n",
      "8466/8466 [==============================] - 16s 2ms/step - loss: 0.0560 - acc: 0.9839\n",
      "Epoch 2/2\n",
      "8466/8466 [==============================] - 15s 2ms/step - loss: 0.0283 - acc: 0.9917\n",
      "Epoch 1/2\n",
      "8467/8467 [==============================] - 24s 3ms/step - loss: 0.0668 - acc: 0.9806\n",
      "Epoch 2/2\n",
      "8467/8467 [==============================] - 21s 2ms/step - loss: 0.0334 - acc: 0.9908\n",
      "Epoch 1/2\n",
      "8467/8467 [==============================] - 25s 3ms/step - loss: 0.0571 - acc: 0.9832\n",
      "Epoch 2/2\n",
      "8467/8467 [==============================] - 21s 3ms/step - loss: 0.0323 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "8466/8466 [==============================] - 23s 3ms/step - loss: 0.0597 - acc: 0.9815\n",
      "Epoch 1/1\n",
      "8467/8467 [==============================] - 23s 3ms/step - loss: 0.0564 - acc: 0.9823\n",
      "Epoch 1/1\n",
      "8467/8467 [==============================] - 24s 3ms/step - loss: 0.0611 - acc: 0.9831\n",
      "Epoch 1/1\n",
      "8466/8466 [==============================] - 26s 3ms/step - loss: 0.0916 - acc: 0.9754\n",
      "Epoch 1/1\n",
      "8467/8467 [==============================] - 21s 2ms/step - loss: 0.0736 - acc: 0.9782\n",
      "Epoch 1/1\n",
      "8467/8467 [==============================] - 21s 2ms/step - loss: 0.0771 - acc: 0.9757\n",
      "Epoch 1/1\n",
      "8466/8466 [==============================] - 27s 3ms/step - loss: 0.0773 - acc: 0.9786\n",
      "Epoch 1/1\n",
      "8467/8467 [==============================] - 27s 3ms/step - loss: 0.0865 - acc: 0.9757\n",
      "Epoch 1/1\n",
      "8467/8467 [==============================] - 34s 4ms/step - loss: 0.0890 - acc: 0.9751\n",
      "Epoch 1/1\n",
      "8466/8466 [==============================] - 23s 3ms/step - loss: 0.0657 - acc: 0.9784\n",
      "Epoch 1/1\n",
      "8467/8467 [==============================] - 22s 3ms/step - loss: 0.0698 - acc: 0.9771\n",
      "Epoch 1/1\n",
      "8467/8467 [==============================] - 22s 3ms/step - loss: 0.0644 - acc: 0.9806\n",
      "Epoch 1/2\n",
      "12700/12700 [==============================] - 43s 3ms/step - loss: 0.0542 - acc: 0.9847\n",
      "Epoch 2/2\n",
      "12700/12700 [==============================] - 41s 3ms/step - loss: 0.0308 - acc: 0.9923\n",
      "The parameters of the best model are: \n",
      "{'pool_size': 2, 'kernel_size': 3, 'filters': 8, 'epochs': 2, 'dense_layer_sizes': [64, 64], 'batch_size': 8}\n"
     ]
    }
   ],
   "source": [
    "validator = RandomizedSearchCV(my_classifier,\n",
    "                               param_distributions=param_dist,\n",
    "                               scoring='neg_log_loss',\n",
    "                               n_jobs=1)\n",
    "history = validator.fit(x_train, y_train)\n",
    "\n",
    "print('The parameters of the best model are: ')\n",
    "print(validator.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ee8285abb0fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# validator.best_estimator_ returns sklearn-wrapped version of best model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# validator.best_estimator_.model returns the (unwrapped) keras model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmetric_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmetric_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'validator' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# validator.best_estimator_ returns sklearn-wrapped version of best model.\n",
    "# validator.best_estimator_.model returns the (unwrapped) keras model\n",
    "best_model = validator.best_estimator_.model\n",
    "metric_names = best_model.metrics_names\n",
    "metric_values = best_model.evaluate(x_test, y_test)\n",
    "for metric, value in zip(metric_names, metric_values):\n",
    "    print(metric, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'RandomizedSearchCV' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d3384c6f15a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Get training and test accuracy histories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtraining_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'RandomizedSearchCV' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Get training and test accuracy histories\n",
    "training_accuracy = history['acc']\n",
    "test_accuracy = history['val_acc']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_accuracy) + 1)\n",
    "\n",
    "# Visualize accuracy history\n",
    "plt.plot(epoch_count, training_accuracy, 'r--')\n",
    "plt.plot(epoch_count, test_accuracy, 'b-')\n",
    "plt.legend(['Training Accuracy', 'Test Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.show();\n",
    "\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
