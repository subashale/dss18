{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alemag/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy = True\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'Devol/')\n",
    "from devol import DEvol, GenomeHandler\n",
    "\n",
    "from Two_Class_MNIST import TwoClassMnist as tcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (12700, 28, 28, 1)\n",
      "12700 train samples\n",
      "2167 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, input_shape = tcm.returnDataSet(1, 2, 28)\n",
    "dataset = ((x_train, y_train), (x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genome Confiugration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_conv_layers = 2\n",
    "max_dense_layers = 2 # including final softmax layer\n",
    "max_conv_kernals = 256\n",
    "max_dense_nodes = 1024\n",
    "#input_shape = x_train.shape[1:]\n",
    "num_classes = 2\n",
    "\n",
    "genome_handler = GenomeHandler(max_conv_layers, max_dense_layers, max_conv_kernals, \\\n",
    "                    max_dense_nodes, input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and run the genetic program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genome encoding and accuracy data stored at Thu Jun 14 19:17:46 2018.csv \n",
      "\n",
      "\n",
      "model 1/2 - generation 1/3:\n",
      "\n",
      "WARNING:tensorflow:From /home/alemag/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Train on 12700 samples, validate on 2167 samples\n",
      "Epoch 1/1\n",
      "12700/12700 [==============================] - 50s 4ms/step - loss: 0.0992 - acc: 0.9817 - val_loss: 0.0205 - val_acc: 0.9958\n",
      "\n",
      "model 2/2 - generation 1/3:\n",
      "\n",
      "Train on 12700 samples, validate on 2167 samples\n",
      "Epoch 1/1\n",
      "12700/12700 [==============================] - 12s 980us/step - loss: 0.0599 - acc: 0.9820 - val_loss: 0.0224 - val_acc: 0.9945\n",
      "An error occurred and the model could not train. Assigned poor score.\n",
      "Generation 1:\t\tbest accuracy: 0.9958\t\taverage: 0.7479\t\tstd: 0.2479\n",
      "\n",
      "model 1/2 - generation 2/3:\n",
      "\n",
      "Train on 12700 samples, validate on 2167 samples\n",
      "Epoch 1/1\n",
      "12700/12700 [==============================] - 53s 4ms/step - loss: 0.1187 - acc: 0.9837 - val_loss: 0.0398 - val_acc: 0.9940\n",
      "\n",
      "model 2/2 - generation 2/3:\n",
      "\n",
      "Train on 12700 samples, validate on 2167 samples\n",
      "Epoch 1/1\n",
      "12700/12700 [==============================] - 51s 4ms/step - loss: 0.1024 - acc: 0.9826 - val_loss: 0.2251 - val_acc: 0.9465\n",
      "An error occurred and the model could not train. Assigned poor score.\n",
      "Generation 2:\t\tbest accuracy: 0.9940\t\taverage: 0.7470\t\tstd: 0.2470\n",
      "\n",
      "model 1/2 - generation 3/3:\n",
      "\n",
      "Train on 12700 samples, validate on 2167 samples\n",
      "Epoch 1/1\n",
      "12700/12700 [==============================] - 471s 37ms/step - loss: 8.5396 - acc: 0.4691 - val_loss: 8.4421 - val_acc: 0.4762\n",
      "\n",
      "model 2/2 - generation 3/3:\n",
      "\n",
      "Train on 12700 samples, validate on 2167 samples\n",
      "Epoch 1/1\n",
      "12700/12700 [==============================] - 65s 5ms/step - loss: 0.0666 - acc: 0.9864 - val_loss: 0.0926 - val_acc: 0.9755\n",
      "An error occurred and the model could not train. Assigned poor score.\n",
      "Generation 3:\t\tbest accuracy: 0.5000\t\taverage: 0.4881\t\tstd: 0.0119\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 128)       18560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 50178     \n",
      "=================================================================\n",
      "Total params: 69,474\n",
      "Trainable params: 69,186\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n",
      "CPU times: user 34min, sys: 3min 4s, total: 37min 4s\n",
      "Wall time: 14min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_generations = 2\n",
    "population_size = 3\n",
    "num_epochs = 4\n",
    "\n",
    "devol = DEvol(genome_handler)\n",
    "model = devol.run(dataset, num_generations, population_size, num_epochs)\n",
    "model.summary()\n",
    "\n",
    "model.save('GAModelWithTB.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2a603ec79207>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "history = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('GAModelWithTB.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model/normal_mnist_keras.h5')\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plotnormal.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layers': [<keras.layers.convolutional.Conv2D object at 0x7ff623f9ccc0>, <keras.layers.normalization.BatchNormalization object at 0x7ff623fb1780>, <keras.layers.core.Activation object at 0x7ff623fb1b00>, <keras.layers.core.Dropout object at 0x7ff623fb18d0>, <keras.layers.pooling.MaxPooling2D object at 0x7ff623fb1438>, <keras.layers.convolutional.Conv2D object at 0x7ff623fda5c0>, <keras.layers.normalization.BatchNormalization object at 0x7ff5f9798780>, <keras.layers.core.Activation object at 0x7ff632d9ef28>, <keras.layers.core.Dropout object at 0x7ff6282eadd8>, <keras.layers.core.Flatten object at 0x7ff6287bfe10>, <keras.layers.core.Dense object at 0x7ff6282db668>], 'model': <keras.engine.training.Model object at 0x7ff5f84739b0>, 'inputs': [<tf.Tensor 'conv2d_1_input:0' shape=(?, 28, 28, 1) dtype=float32>], 'outputs': [<tf.Tensor 'dense_1/Softmax:0' shape=(?, 2) dtype=float32>], '_trainable': True, '_initial_weights': None, '_inbound_nodes': [<keras.engine.topology.Node object at 0x7ff623f9cc88>], '_outbound_nodes': [], '_built': True, 'name': 'sequential_1', 'supports_masking': False, '_output_mask_cache': {'140695142339864_94878054939248': None}, '_output_tensor_cache': {}, '_output_shape_cache': {}, 'input_layers': [<keras.engine.topology.InputLayer object at 0x7ff623f9ce10>], 'input_layers_node_indices': [0], 'input_layers_tensor_indices': [0], 'output_layers': [<keras.layers.core.Dense object at 0x7ff6282db668>], 'output_layers_node_indices': [0], 'output_layers_tensor_indices': [0], '_nodes_by_depth': {0: [<keras.engine.topology.Node object at 0x7ff5f8525f98>], 1: [<keras.engine.topology.Node object at 0x7ff5f84fe908>], 2: [<keras.engine.topology.Node object at 0x7ff6282dbdd8>], 3: [<keras.engine.topology.Node object at 0x7ff6282db710>], 4: [<keras.engine.topology.Node object at 0x7ff5f8800710>], 5: [<keras.engine.topology.Node object at 0x7ff6282fc828>], 6: [<keras.engine.topology.Node object at 0x7ff5f8380438>], 7: [<keras.engine.topology.Node object at 0x7ff5f9798c88>], 8: [<keras.engine.topology.Node object at 0x7ff6287e9dd8>], 9: [<keras.engine.topology.Node object at 0x7ff623fdad68>], 10: [<keras.engine.topology.Node object at 0x7ff623f9c7f0>], 11: [<keras.engine.topology.Node object at 0x7ff623f9cb70>]}, 'output_names': ['dense_1'], 'input_names': ['conv2d_1_input'], '_feed_input_names': ['conv2d_1_input'], '_feed_inputs': [<tf.Tensor 'conv2d_1_input:0' shape=(?, 28, 28, 1) dtype=float32>], '_container_nodes': {'conv2d_1_ib-0', 'activation_2_ib-0', 'dense_1_ib-0', 'conv2d_2_ib-0', 'flatten_1_ib-0', 'dropout_2_ib-0', 'activation_1_ib-0', 'conv2d_1_input_ib-0', 'dropout_1_ib-0', 'max_pooling2d_1_ib-0', 'batch_normalization_1_ib-0', 'batch_normalization_2_ib-0'}, 'optimizer': <keras.optimizers.Adam object at 0x7ff623f9ce80>, 'loss': 'categorical_crossentropy', 'metrics': ['accuracy'], 'loss_weights': None, 'sample_weight_mode': None, 'weighted_metrics': None, 'targets': [<tf.Tensor 'dense_1_target:0' shape=(?, ?) dtype=float32>], 'metrics_tensors': [<tf.Tensor 'metrics/acc/Mean:0' shape=() dtype=float32>], 'metrics_names': ['loss', 'acc'], 'sample_weights': [<tf.Tensor 'dense_1_sample_weights:0' shape=(?,) dtype=float32>], 'total_loss': <tf.Tensor 'loss/mul:0' shape=() dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "print(vars(history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9264ac4d3215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get training and test accuracy histories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create count of the number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "# Get training and test accuracy histories\n",
    "training_accuracy = history.history['acc']\n",
    "test_accuracy = history.history['val_acc']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_accuracy) + 1)\n",
    "\n",
    "# Visualize accuracy history\n",
    "plt.plot(epoch_count, training_accuracy, 'r--')\n",
    "plt.plot(epoch_count, test_accuracy, 'b-')\n",
    "plt.legend(['Training Accuracy', 'Test Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.show();\n",
    "\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
